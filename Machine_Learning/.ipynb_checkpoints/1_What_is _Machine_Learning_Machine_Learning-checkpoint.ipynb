{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align=\"right\">Machine Learning\n",
    "### <div align=\"right\"> *Followblindly*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - What is Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > **Arthur Samuel (1959)**. *Machine Learning: The field of study that gives computers the ability to learn without being explicitly learned*.\n",
    " \n",
    " > **Tom Mitchell (1998)**. *Well-posed Learning Problem: a computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience E*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms Grouped By Similarity\n",
    "\n",
    "There are different ways an algorithm can model a problem based on its interaction with the experience or environment or whatever we want to call the input data. It is popular in machine learning and artificial intelligence textbooks to first consider the learning styles that an algorithm can adopt. \n",
    "\n",
    "This taxonomy or way of organizing machine learning algorithms is useful because it forces you to think about the roles of the input data and the model preparation process and select one that is the most appropriate for your problem in order to get the best result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised Learning Algorithms \n",
    "\n",
    "In supervised learning, we are given a data set and **already know what our correct output** should look like, having the idea that there is a relationship between the input and the output.\n",
    "\n",
    "Supervised learning problems are categorized into **\"Regression\"** and **\"Classification\"** problems. In a regression problem, we are trying to predict results within a continuous output, meaning that we are trying to map input variables to some continuous function. In a classification problem, we are instead trying to predict results in a discrete output. In other words, we are trying to map input variables into discrete categories. \n",
    "\n",
    "* **Examples of Supervised Learning:**  Regression, Decision Tree, Random Forest, KNN, Logistic Regression etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised Learning Algorithms\n",
    "\n",
    "In unsupervised learning, the data has no labels. Unsupervised learning allows us to approach problems with **little or no idea** what our results should look like. We can derive structure from data where we don't necessarily know the effect of the variables. We can derive this structure by **Clustering** the data based on relationships among the variables in the data. With unsupervised learning there is no feedback based on the prediction results.\n",
    "\n",
    "* **Examples of Unsupervised Learning:**  Apriori algorithm, K-means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reinforcement Learning Algorithms\n",
    "\n",
    "Lastly, we have reinforcement learning, the latest frontier of machine learning. A reinforcement algorithm learns by trial and error to achieve a clear objective. It tries out lots of different things and is **rewarded** or **penalized** depending on whether its behaviors help or hinder it from reaching its objective. This is like giving and withholding treats when teaching a dog a new trick. Reinforcement learning is the basis of Googleâ€™s AlphaGo, the program that famously beat the best human players in the complex game of Go.\n",
    "\n",
    "* **Example of Reinforcement Learning:** Markov Decision Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms Grouped By Similarity\n",
    "\n",
    "Algorithms are often grouped by similarity in terms of their function (how they work). For example, tree-based methods, and neural network inspired methods. This is a useful grouping method, but it is not perfect. There are still algorithms that could just as easily fit into multiple categories like Learning Vector Quantization that is both a neural network inspired method and an instance-based method. There are also categories that have the same name that describe the problem and the class of algorithm such as Regression and Clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Algorithms "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression is concerned with modeling the relationship between variables that is iteratively refined using a measure of error in the predictions made by the model. Regression methods are a workhorse of statistics and have been co-opted into statistical machine learning. This may be confusing because we can use regression to refer to the class of problem and the class of algorithm. Really, regression is a process.\n",
    "\n",
    "The most popular regression algorithms are:\n",
    "\n",
    "* Ordinary Least Squares Regression (OLSR)\n",
    "* Linear Regression\n",
    "* Logistic Regression\n",
    "* Stepwise Regression\n",
    "* Multivariate Adaptive Regression Splines (MARS)\n",
    "* Locally Estimated Scatterplot Smoothing (LOESS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
